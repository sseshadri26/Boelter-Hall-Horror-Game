# DEV LOG -- UI Team

## About
This is a simple log for tracking the current and past challenges taken on by the UI programming team over the course of the project. We're doing this to keep a record of *why* we're making the choices that we are so that it's easier to understand how the codebase came to be and how to improve it.

## Log

### (5/29)
**Problem:** We would like to be able to navigate UI via controller in addition to mouse for those playing with a controller only.
- Option 1: Design an interface for interacting with UIPanels via directional input (WASD or controller) called `IDirectionControllable`. `UIController` will then operate on panels that implement this interface and map the directional inputs accordingly to the methods of the panels.
- Option 2: Implement handlers for navigation callbacks directly from the New Input System's input module with something like `RegisterCallback<NavigationMoveEvent>()` that automatically click buttons when they're navigated to.
- Option 3: Use a separate component that controls a given panel based on directional input. This requires making a separate component for each general panel type, but comes with the benefit of not requiring modification of any of the panel scripts.
- **Resolution:** Option 1 is the more familiar option and thus will probably be faster for me to implement. However, Option 2 could potentially require less code change in the sense that no additional modules need to be modified other than the panels themselves (as opposed to the UI controller and the additional interface). Option 3 seemed to be overly complex and not that beneficial given how easy it is to modify the panel scripts.

### (5/27)
**Problem:** How should we implement map disable in the tab panel? The player does not have the map immediately from the beginning, so the button to access the map from the tab panel should not be clickable. How do we prevent the button from being clicked, and how do we tell the tab panel to disable the map button?
- Option 1: Don't add the map button visual to the tab and then add it when it gets unlocked. This should make selection logic a lot easier since the button simply won't be there to click. Requires refactoring script to handle dynamic tabs, which can be costly, especially since the UI is already hard-coded for 3 tabs.
- Option 2: Have fixed-number of slots, but allow dynamic assignment of those slots. This allows us to keep our simple hard-coded visuals without needing to change much other than add a USS class for the unfilled slot visual and functionality for filling a new slot.
- **Resolution:** Option 2 seemed to be a nice compromise between complexity and flexibility for the scope of this problem (where we realistically will probably only need to add 1 - 2 tabs after game start). I have been able to implement dynamic tab creation up to the maximum number of visual slots the UXML supports. It comes with the beneficial side effect of also hinting at the number of tabs that have yet to be unlocked (since unlocked slots are still visually there but do not have a name and are not clickable).

### (4/21)
**Problem:** Providing the user with an API that lets them animate the panel from any part of the screen is complex given that the `UI Elements` update loop is complete separate from the standard `Monobehaviours` update loop. Thus, animations queued during a game frame may not reflect in the UI until several frames after -- whenever the UI update occurs. What are my options for implementing this behavior?
- Option 1: Trigger a "set up" animation to position the panel in the proper starting position and then assign a callback to the `TransitionEndEvent` for the panel's `VisualElement` that then triggers the main animation to animate the panel into the center of the screen. While this does implement the desired behavior, it leaves the implementation open to errors since any animations invoked on the panel's `VisualElement`, not necessarily just the "set up animation" would trigger the `TransitionEndEvent`. Thus, it's easy to accidentally trigger the callback and cause undesired behavior.
- Option 1A: One variation might be to look at special identifiers in the event object, which would add more complexity but would resolve the issue of ambiguity of what's invoking the event.
- Option 2: Simplify the API so that the user can only specify *when* to open the panel with `FadeInPanel()` and not where to open the panel from. This would mean that `PanelAnimator.cs` would not have to move the panel beforehand but instead just animate from its last exit position. While this reduces the use cases for the API, we realistically don't need most of those use cases (if a panel is animated out of screen to the left, then the user would expect the panel to come back out from the left).
- **Resolution:** After some searching, I discovered that you can easily run a piece of logic after the UI has updated using the `VisualElement.schedule.Execute()` method. Thus, programming two separate UI changes -- one to initialize a start position and one to perform the main animation -- was now more doable since the main animation could simply be scheduled to trigger after the position has been initialized. Even though the implementation for this approach was still slightly more complicated than the others, it has the benefit of not needing to keep track of as much state for the panel, since every animation start position is specified by the user.

### (4/19)
**Problem:** Now that UI animation has been decoupled from other systems pretty well, I'm ready to begin applying it to new problems. The current problem is with the tab panel. The tab panel is supposed to serve as a collection of other UI panels. It should have the ability to swap in different UI panels by clicking different tabs at the top of the screen. I want panels to be animated onto the main stage such that it looks like one continuous strip that's being cycled around (see Harry Potter Puzzles and Spells home screen). How should I implement this?

- With the current API of `PanelAnimator.cs`, it is only possible to animate in a predefined way (you choose one of 6 animations hard-coded into the implementation). I could just define one more animation in the code, but I don't want to have to keep hard-coding a new animation every time I need something different.
- What if I pass up more control over the animation into the API? For example, the user could specify to animate an item into the screen with a specified animation and then animate out of the screen with a specified animation.
- **Resolution:** Modify the API so that now the user can specify animation details. Something like `FadeInPanel(Position startPos)`, `FadeOutPanel(Position endPos)`, `AppearInPanel()`, and `AppearOutPanel()`. Now, the user has much more control over how the animation will pan out. The only downside I can think of is that the API becomes more complex, and thus the systems that use it become more complex. However, this additional complexity is not much and more than made up for in the range of problems `PanelAnimator.cs` can now be applied to.

### (3/21)
**Problem:** The inventory UI panel has a special feature where key items are marked in a special color. How do we allow this unique functionality to be injected into the main `AlamancUI.cs` code?
- It's important to keep in mind the pattern of separating visuals from behavior. A good solution would be one that shifted the changing of the item colors to the UI itself. Sounds like USS classes could be used here?
- Define an AlamanacUI USS class called `marked` or something in order to apply the special formatting to the given item. While this does inherently couple the marking feature to being an AlmanacUI even when not all alamanacs will use it, I think it's small enough of a feature that the coupling won't be too significant even in the worst case where no other almanac uses it.
- I tried using inheritance with derived classes handling styling of list item UI. It worked well except for the fact that derived classes are stuck dealing with abstract `ItemSO` objects that hide important details the derived classes need to use (for example, InventoryUI needs to know specific properties that `InventoryItemSO` has but not `ItemSO`). I could have just casted `ItemSO` references to `InventoryItemSO`, but then it would require a runtime check that may cause some confusing errors. 

- **Resolution:** Use a component-based approach where a separate component is responsible for generating the UI for the individual item elements. This way, there is a compile time check on the type of the item collection/items (for example, we are guaranteed it is `InventoryItemSO` and not `JournalItemSO` at compile time -- in fact the editor won't even let you use it). This way, we catch bugs earlier at the cost of a little bit of complexity with adding a brand new component.

### (3/16)
**Problem:** Both Inventory and Journal UI panels essentially have the same functionality but just different visual representations (a list of items that let you view each in more detail). How do we reduce code repeat?
- Need a strategy for separating visuals from functionality.
- The whole point of `UIElements` is to cleanly separate UI design from UI code. How can we leverage this separation? Well it seems like the paradigm is to simply agree to use the same class names. But what about slight differences between Inventory and Journal like the ability to highlight names in the Inventory? As long as there aren't too many of these differences, we can just have special class names that only appear in some UI designs but not others.
- **Resolution:** Standardize the class names used in almanac-style UI. For example, there should be a `main-title` class for representing the text component for the currently selected item. We can use a single class to provide the functionality for both the Inventory and Journal panels called `AlamanacUI.cs` or something like that. This class would also leave the individual item card UIs to be injected just like `InventoryUI.cs` currently does. Note that we don't want to just be injecting everything since that would make the code more complex, far too complex for the scale of code reuse we need (probably only used for Inventory, Journal, and maybe one or two more in the future).

### (3/9)
**Problem:** All panels will need functionality to enter/exit the screen. How do we implement this efficiently?
- This is a design choice between inheritance and components. Components are great for building highly-variable behaviors that may use widely different combinations of behaviors. However, you pay for this flexibility with complexity -- you need a system for communication between components and a system for storing them (Unity already does this for you with `GameObject`). Inheritance is simpler to implement but does come with the downside of forcing all derived classes to have certain functionality.

- **Resolution:** Write a base class for all UI panels in the game that has built-in animation functionality. All derived classes need not worry about how to animate the panel in or out. Even though inheritance tightly couples animating to panels, this is fine because pretty much all panels will need some way to animate in. Inheritance is simpler to implement and understand than other options, so it seemed like a reasonable choice.

- **Revision (4/19):** It turns out that animation has practically nothing to do with the behavior of most UI. Thus, it makes more sense for animation behavior to be encapsulated within a component that can be placed on any piece of UI. I reasoned previously that the simplicity of inheritance makes it a reasonable choice. However, inheritance ended up just making the UI behaviors more tedious to implement (required overriding `Awake` and having to remember to call `base.Awake()`) and more confusing (animation has nothing to do with this class, so why is it the parent?). Thus, I refactored it to be component-based.

### (2/12)
**Problem:** Making scripts that interface with the controls on a UI Document is tedious!
- It's a tedious process of scanning through all the buttons or text fields (or whatever) and explicitly writing code to address each one.
- **Resolution:** Make an editor tool that auto-generates a script for a specified UI Document. While this will require a lot of effort up front, we believe it will pay back huge dividends later on, especially for some of the more complex UI in the game.

### (2/6)
**Problem:** What strategy do we employ to wire up the UI events to the main game?
- For buttons/input widgets that interact with the game, such as resume, restart, main menu, etc., we could send out a message through a `ScriptableObject` channel that the game listens to. 
- An alternative would be to use a `static` class as the interface between the UI and the game, with public events exposed. Global data/functions are always dangerous because they can impact who knows how many other pieces of code tied to them -- their scope is unknowable. The fact that a `static` event would be accessible from all parts of the codebase means it's super easy for developers to add code that either calls it or acts when it's called, meaning it gets super hard to debug since there are so many ways that event could have been triggered and so many different parts of the code that may have been modified because of it.
- Note that a `static` class could also serve as a channel like `ScriptableObject` can, with the main difference being that it's publicly accessible. The whole point of a channel is that it's a stable interface: all other modules that tie themselves to it (on either the receiving or sending end) won't have to worry about changing their code that interacts with the interface that frequently (since the interface is unlikely to change).

- **Resolution:** We will use `ScriptableObject` for event channels. The antidote to global data is dependency injection. Here, we are *injecting* our event channel object into the modules that use them instead of fetching it ourselves through a global class, making the decision to link up to an event channel more intentional and less prone to errors caused by carelessness. Not only this, but I've made a Unity editor tool in the past that already tests `ScriptableObject` channels, so the overhead of creating a testing framework is mostly already covered.

**Problem:** What data should the Pause Menu pass to the game controller?
- Creating a separate event channel for each possible message (like `OnResumePressed`, `OnRestartPressed`, etc.) seems like overkill since the `GameManager` will need to specifically subscribe to each of these events, which can be tedious. The key point here is that each of these individual events would likely be handled by the same subscriber(s), so there's not much point to splitting them off.
- **Resolution:** An alternative would be to have a single event channel for game state manipulation, and enums representing different commands like `RESUME`, `RESTART`, or `GO_MAIN_MENU` could be passed through. Currently, we don't see any significant disadvantages of doing it this way than having a dedicated channel for each.

### (2/5)
**Problem:** UI Toolkit or Old UI System?
- UI Toolkit makes it easier to design precise UI, but comes with the drawback of having only rough documentation and more complex implementations
- **Resolution:** We are chosing to use UI Toolkit to better manage the complex structure of the game's UI, which currently requires tabbed panels, embedded diagrams (like for items and the map), in addition to "stack" panels that require scrolling to view different items. Additionally, since UI Toolkit is the direction Unity is currently moving in, we reason that using it will help the project's UI stay supported far into the future.

